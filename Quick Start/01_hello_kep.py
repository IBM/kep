#!/usr/bin/env python3
"""
01_hello_kep.py - Introduction to the Knowledge Extraction Pipeline

This script provides a comprehensive introduction to KEP, explaining its
capabilities, architecture, and use cases.

Run this script to learn:
- What KEP does and why it's useful
- How the pipeline works (Convert â†’ Classify â†’ Extract)
- Real-world applications and examples
- System requirements and setup overview

Usage:
    python "01_hello_kep.py"
"""

import sys
import os
from pathlib import Path

# ASCII Art Logo
LOGO = """
    â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— 
    â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—
    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
    â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â•â• 
    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘     
    â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•     
                            
Knowledge Extraction Pipeline
"""

def print_header(title, char="=", width=60):
    """Print a formatted header"""
    print()
    print(char * width)
    print(f" {title}")
    print(char * width)

def print_section(title, char="-", width=50):
    """Print a formatted section header"""
    print()
    print(f"{title}")
    print(char * len(title))

def main():
    """Main introduction to KEP"""
    
    # Welcome
    print(LOGO)
    print("ğŸš€ Welcome to the Knowledge Extraction Pipeline!")
    print("   A scalable system for transforming unstructured scientific")
    print("   documents into structured knowledge using foundation models.")
    print()
    
    # What is KEP?
    print_header("ğŸ“‹ What is KEP?")
    print()
    print("The Knowledge Extraction Pipeline (KEP) is an end-to-end system that")
    print("processes scientific documents and extracts structured information using")
    print("Large Language Models (LLMs).")
    print()
    print("ğŸ¯ Core Mission:")
    print("   Transform PDFs full of unstructured text into clean,")
    print("   structured JSON data that follows YOUR custom schema.")
    
    # How it works
    print_header("ğŸ”„ How KEP Works - The Three-Stage Pipeline")
    print()
    print("KEP follows a simple but powerful three-stage process:")
    print()
    print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("â”‚   CONVERT   â”‚ -> â”‚   CLASSIFY   â”‚ -> â”‚   EXTRACT   â”‚")
    print("â”‚   PDF â†’ MD  â”‚    â”‚ Relevant vs  â”‚    â”‚ Structured  â”‚")
    print("â”‚   + Chunks  â”‚    â”‚ Irrelevant   â”‚    â”‚    JSON     â”‚")
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    print()
    
    print_section("Stage 1: CONVERT ğŸ“„")
    print("â€¢ Converts PDF files to Markdown using Docling")
    print("â€¢ Splits documents into logical paragraphs or chunks")
    print("â€¢ Preserves structure while making text LLM-friendly")
    print("â€¢ Handles tables, figures, and complex layouts")
    
    print_section("Stage 2: CLASSIFY ğŸ·ï¸")
    print("â€¢ Uses LLM to classify each paragraph as 'relevant' or 'irrelevant'")
    print("â€¢ Based on YOUR classification schema and examples")
    print("â€¢ Filters out noise, keeping only content that matters")
    print("â€¢ Supports both zero-shot and few-shot classification")
    
    print_section("Stage 3: EXTRACT ğŸ—ï¸")
    print("â€¢ Processes only the 'relevant' paragraphs from Stage 2")
    print("â€¢ Extracts structured data following YOUR custom JSON schema")
    print("â€¢ Returns clean, consistent JSON output")
    print("â€¢ Includes metadata and provenance tracking")
    
    # Key Features
    print_header("âœ¨ Key Features")
    print()
    features = [
        ("ğŸŒŠ Fully Streamed", "No intermediate databases, minimal memory usage"),
        ("ğŸ”Œ Provider Agnostic", "Works with WatsonX, RITS, and extensible to others"),
        ("ğŸ“‹ Schema-Driven", "Define your own classification and extraction schemas"),
        ("ğŸ¯ Few-Shot Learning", "Include examples directly in schema files"),
        ("ğŸ“Š Rich Logging", "Comprehensive metadata and debugging support"),
        ("âš¡ Scalable", "Process single PDFs or large document collections"),
        ("ğŸ”§ Customizable", "Flexible chunking, prompting, and model selection"),
        ("ğŸ›¡ï¸ Robust", "Error handling, retry logic, and graceful degradation")
    ]
    
    for feature, description in features:
        print(f"   {feature}: {description}")
    
    # Real-world applications
    print_header("ğŸ”¬ Real-World Applications")
    print()
    
    applications = [
        ("ğŸ§ª Materials Science", "Extract material properties, synthesis methods, performance metrics"),
        ("ğŸ’Š Drug Discovery", "Identify compounds, mechanisms, clinical trial results"),
        ("ğŸŒ± Environmental Research", "Parse pollution data, environmental impacts, policy measures"),
        ("âš¡ Energy Research", "Extract battery specifications, solar cell efficiency, energy storage"),
        ("ğŸ­ Manufacturing", "Process protocols, quality metrics, operational parameters"),
        ("ğŸ“š Literature Reviews", "Systematic extraction across hundreds of research papers"),
        ("ğŸ¥ Medical Research", "Clinical data, treatment outcomes, diagnostic information"),
        ("ğŸ”¬ Chemical Engineering", "Process conditions, reaction parameters, optimization results")
    ]
    
    for domain, description in applications:
        print(f"   {domain}")
        print(f"      {description}")
        print()
    
    # Example workflow
    print_header("ğŸ“– Example: Battery Research Workflow")
    print()
    print("Scenario: You have 50 PDFs about lithium-ion battery materials")
    print("Goal: Extract all battery performance data into a structured database")
    print()
    print("1ï¸âƒ£ SETUP:")
    print("   â€¢ Create classification schema: 'battery_related' vs 'not_battery_related'")
    print("   â€¢ Create extraction schema: materials, capacity, voltage, cycle_life")
    print("   â€¢ Add example paragraphs to schemas for few-shot learning")
    print()
    print("2ï¸âƒ£ EXECUTION:")
    print("   â€¢ Run: python run_pipeline.py --pdf-dir ./battery_pdfs \\")
    print("           --cls-schema ./schemas/battery_classification.json \\")
    print("           --ext-schema ./schemas/battery_extraction.json")
    print()
    print("3ï¸âƒ£ RESULTS:")
    print("   â€¢ classified_relevant.json: Only battery-related paragraphs")
    print("   â€¢ structured.json: Clean JSON with all extracted data")
    print("   â€¢ Rich metadata: Processing stats, model info, debug logs")
    print()
    print("4ï¸âƒ£ IMPACT:")
    print("   â€¢ Hours â†’ Minutes: What took days of manual reading now takes minutes")
    print("   â€¢ Consistency: No human bias or fatigue in extraction")
    print("   â€¢ Scalability: Process thousands of papers with same effort")
    print("   â€¢ Traceability: Every extraction links back to source paragraph")
    
    # Architecture overview
    print_header("ğŸ—ï¸ System Architecture")
    print()
    print("KEP is built with a modular, extensible architecture:")
    print()
    print("ğŸ“ Core Components:")
    print("   â€¢ ingest/: PDF processing and text chunking (Docling integration)")
    print("   â€¢ llm/: Provider-agnostic LLM interfaces (WatsonX, RITS, extensible)")
    print("   â€¢ extractor/: Classification and extraction logic")
    print("   â€¢ prompter/: Template-based prompting system")
    print("   â€¢ common/: Logging, metadata, and utility functions")
    print()
    print("ğŸ”Œ LLM Provider System:")
    print("   â€¢ Factory pattern for easy provider switching")
    print("   â€¢ Unified interface regardless of backend")
    print("   â€¢ Environment-based configuration")
    print("   â€¢ Extensible to new providers (OpenAI, Anthropic, etc.)")
    print()
    print("ğŸ“‹ Schema System:")
    print("   â€¢ JSON-based schema definitions")
    print("   â€¢ Embedded examples for few-shot learning")
    print("   â€¢ Validation and error checking")
    print("   â€¢ Version control friendly")
    
    # What makes KEP special
    print_header("ğŸŒŸ What Makes KEP Special?")
    print()
    special_features = [
        ("Research-First Design", "Built specifically for scientific document processing"),
        ("Production Ready", "Robust error handling, logging, and monitoring"),
        ("Schema-Driven Approach", "Your domain knowledge guides the extraction"),
        ("Transparent Processing", "Full audit trail from input to output"),
        ("Provider Independence", "Not locked into any single LLM service"),
        ("Extensible Architecture", "Easy to add new providers, models, or features"),
        ("Example-Driven Learning", "Few-shot examples improve accuracy significantly"),
        ("Comprehensive Tooling", "Complete ecosystem from setup to analysis")
    ]
    
    for feature, description in special_features:
        print(f"   ğŸ¯ {feature}:")
        print(f"      {description}")
        print()
    
    # System requirements
    print_header("ğŸ’» System Requirements")
    print()
    print("ğŸ“‹ Minimum Requirements:")
    print("   â€¢ Python 3.8 or higher")
    print("   â€¢ 4GB RAM (8GB+ recommended for large documents)")
    print("   â€¢ Internet connection for LLM API calls")
    print("   â€¢ ~500MB disk space for dependencies")
    print()
    print("ğŸ”‘ Required Access:")
    print("   â€¢ IBM Cloud account with WatsonX access, OR")
    print("   â€¢ RITS API access, OR")
    print("   â€¢ Custom LLM provider (extensible)")
    print()
    print("ğŸ“¦ Dependencies:")
    print("   â€¢ ibm-watsonx-ai: WatsonX integration")
    print("   â€¢ docling: Advanced PDF processing")
    print("   â€¢ nltk: Natural language processing")
    print("   â€¢ pyyaml: Configuration management")
    print("   â€¢ rich: Beautiful terminal output")
    print("   â€¢ See requirements.txt for complete list")
    
    # Next steps
    print_header("ğŸ¯ Next Steps")
    print()
    print("Ready to get started? Here's your roadmap:")
    print()
    print("1ï¸âƒ£ Environment Check:")
    print("   python \"02_environment_check.py\"")
    print("   â†’ Verify Python, dependencies, and KEP installation")
    print()
    print("2ï¸âƒ£ Test Connections:")
    print("   python \"03_test_connections.py\"")
    print("   â†’ Validate LLM provider access and authentication")
    print()
    print("3ï¸âƒ£ Understand Schemas:")
    print("   python \"04_understanding_schemas.py\"")
    print("   â†’ Learn how to create effective schemas")
    print()
    print("4ï¸âƒ£ Run Demo Pipeline:")
    print("   python \"05_pipeline_demo.py\"")
    print("   â†’ Execute your first complete extraction")
    print()
    print("5ï¸âƒ£ Explore Results:")
    print("   python \"06_results_explorer.py\"")
    print("   â†’ Understand and analyze pipeline outputs")
    print()
    print("6ï¸âƒ£ Create Custom Schemas:")
    print("   python \"07_custom_schemas.py\"")
    print("   â†’ Build schemas for your specific domain")
    print()
    print("7ï¸âƒ£ Advanced Diagnostics:")
    print("   python \"08_troubleshooting.py\"")
    print("   â†’ Comprehensive system health check")
    
    # Success stories
    print_header("ğŸ“ˆ Success Stories")
    print()
    print("KEP has been successfully used for:")
    print()
    print("ğŸ† PFAS Research:")
    print("   â€¢ Processed 1000+ environmental papers")
    print("   â€¢ Extracted chemical properties and health impacts")
    print("   â€¢ Reduced analysis time from weeks to hours")
    print()
    print("ğŸ† Battery Materials:")
    print("   â€¢ Analyzed 500+ papers on energy storage")
    print("   â€¢ Built comprehensive materials database")
    print("   â€¢ Identified performance trends across decades")
    print()
    print("ğŸ† Synthesis Protocols:")
    print("   â€¢ Extracted reaction conditions from 200+ papers")
    print("   â€¢ Standardized diverse reporting formats")
    print("   â€¢ Enabled systematic optimization studies")
    
    # Getting help
    print_header("ğŸ†˜ Getting Help")
    print()
    print("If you need assistance:")
    print()
    print("ğŸ“§ Contact the KEP Team:")
    print("   â€¢ Viviane Torres (Manager): vivianet@br.ibm.com")
    print("   â€¢ Marcelo Archanjo: marcelo.archanjo@ibm.com")
    print("   â€¢ Anaximandro Souza: anaximandrosouza@ibm.com")
    print()
    print("ğŸ“š Documentation:")
    print("   â€¢ README.md: Complete system documentation")
    print("   â€¢ UNIFIED_SETUP.md: Detailed setup instructions")
    print("   â€¢ CLAUDE.md: Developer guidance")
    print()
    print("ğŸ”§ Diagnostics:")
    print("   â€¢ Run: python \"08_troubleshooting.py\"")
    print("   â€¢ Check logs in runs/*/run.log")
    print("   â€¢ Enable --debug-io for detailed LLM traces")
    
    # Conclusion
    print_header("ğŸ‰ Ready to Extract Knowledge?")
    print()
    print("You now understand what KEP can do for your research!")
    print()
    print("KEP transforms the tedious task of reading hundreds of papers")
    print("into an automated, scalable, and accurate extraction process.")
    print()
    print("ğŸš€ Start your journey:")
    print("   python \"02_environment_check.py\"")
    print()
    print("ğŸŒŸ Join the community of researchers using KEP to accelerate")
    print("   scientific discovery through automated knowledge extraction!")
    print()
    print("=" * 60)
    print(" Happy Knowledge Extracting! ğŸ§ âœ¨")
    print("=" * 60)

if __name__ == "__main__":
    main()